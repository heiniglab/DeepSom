{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create variant tensor images\n",
    "\n",
    "We construct variant tensor images for each variant in a given VCF file.\n",
    "\n",
    "When required, data augmentation can be applied by exchanging mutation signatures \n",
    "between piledup reads in a random pair of variants.\n",
    "\n",
    "Output images are grouped in batches of size Lbatch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "from typing import *\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import pysam #library for reading VCF files\n",
    "\n",
    "sys.path.append(\"python/\")\n",
    "\n",
    "from variant_to_image import variant_to_image #function to form image out of a variant"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Auxiliary functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class dotdict(dict):\n",
    "    \"\"\"\n",
    "    Dictionary with dot.notation access to attributes\n",
    "    \"\"\"\n",
    "    __getattr__ = dict.__getitem__\n",
    "    __setattr__ = dict.__setitem__\n",
    "    __delattr__ = dict.__delitem__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dump_batch(batch, info, batch_path): \n",
    "    '''\n",
    "    Write a batch of images on the disk\n",
    "    '''\n",
    "    \n",
    "    #print(batch_path)\n",
    "    \n",
    "    if not SIMULATE:\n",
    "        with open(batch_path, 'wb') as f:\n",
    "            pickle.dump({'images':batch, 'info':info},f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_images(vcf :str,                             #full path to a VCF file with the variants\n",
    "               bam_dir: str,                          #directory with corresponding BAM files\n",
    "               output_dir :str,                       #output dir for images batches\n",
    "               refgen_fa :str,                        #reference genome FASTA file\n",
    "               image_opts :Dict,                      #options for variant tensor encoding\n",
    "               chrom :Optional[str] = None,           #chromosome name\n",
    "               start :Optional[int] = None,           #min position in the chromosome\n",
    "               stop :Optional[int] = None,            #max position in the chromosome\n",
    "               Lbatch :int = 32,                      #how many images put in each batch\n",
    "               bam_matching_csv :str = '',            #matching table between BAM sample name and BAM file name\n",
    "               max_variants :Optional[int] = None,    #stop when this number of variants is reached\n",
    "               data_augmentation :bool = False,         #use data augmentation\n",
    "               data_augmentation_random_state :int = 0  #random state for data augmentation\n",
    "             ):         \n",
    "    '''\n",
    "    Create a pileup image for each variant in the given VCF file.\n",
    "    \n",
    "    For each variant a sample BAM file is required.\n",
    "    BAM file name can be encoded directly as a record BAM=bam_file_name.bam in the VCF INFO field (without the path).\n",
    "    Otherwise, it is inferred from the sample name in the VCF file using bam_matching_csv.\n",
    "    \n",
    "    Images a packed in batches of size Lbatch.\n",
    "    Depending on the global SIMULATE value the batches are saved to the disk.\n",
    "    To avoid file system issues, we distribute batches into subfolders in the output_dir.\n",
    "\n",
    "    To keep record of variants created, variant annotations (DP, VAF etc...) are added to the variants_df dataframe.\n",
    "    To speed up processing, they are first accumulated in variants_list and added to the variants_df only when 1000 variants are accumulated.\n",
    "    \n",
    "    Image options (width, height etc...) are defined in the image_opts dictionary.\n",
    "    See the variant_to_image function to learn more about image options.\n",
    "    \n",
    "    Data augmentation is possible within variants from the given VCF by exchanging mutational context between different pileup images.\n",
    "    '''\n",
    "    \n",
    "    images_per_subdir = 100*Lbatch #maximum images per subdir\n",
    "    \n",
    "    variants_df = pd.DataFrame(columns=[\"vcf\", \"vcf_record_idx\",\"chrom\",\"pos\",\"refpos\",\"ref\",\"alt\",\"ref_support\",\"old_chrom\",\"old_pos\",\"old_refpos\",\"old_ref\",\"old_alt\",\"gnomAD_AF\", \"GERMLINE\", \"BAM\",\"VAF\",\"DP\",\"image_height\", \"batch_name\", \"subdir\"]) # DataFrame for variant annotations \n",
    "    \n",
    "    if not SIMULATE:\n",
    "        os.makedirs(output_dir, exist_ok=True)\n",
    "        \n",
    "    if bam_matching_csv:\n",
    "        #matching table between BAM sample name and BAM file name\n",
    "        #otherwise, the INFO filed of the VCF file should have the BAM=bam_file_name.bam record \n",
    "        bam_matching = pd.read_csv(bam_matching_csv, names=['BAM_sample', 'BAM_file'], squeeze=True, index_col=0)\n",
    " \n",
    "    if data_augmentation:\n",
    "        #replacement_df is a shuffled version of the original VCF\n",
    "        vcf_df = pd.read_csv(input_params.vcf, sep = '\\t', comment = '#', names = ['chrom', 'pos', 'id', 'ref', 'alt', 'qual', 'filter', 'info'])\n",
    "        random_state = data_augmentation_random_state + sum([ord(x) for x in chrom]) #use different random state for each chromosome\n",
    "        replacement_df = vcf_df[['chrom', 'pos', 'ref', 'alt']].sample(frac = 1, random_state = random_state)\n",
    "        replacement_df.chrom = replacement_df.chrom.astype(str)\n",
    "\n",
    "    vcf_in = pysam.VariantFile(vcf) #open the VCF file\n",
    "    \n",
    "    all_samples = list(vcf_in.header.samples) #extract BAM sample names from the VCF header\n",
    "                    \n",
    "    variants_batch = [] #current batch of images\n",
    "        \n",
    "    variants_list = []  #we will first accumulate variant annotations in a list and then add this list to the data frame\n",
    "    \n",
    "    N_variants_added = 0 #total number of variants added\n",
    "        \n",
    "    #iterate over the records of the vcf file\n",
    "    for vcf_record_idx, rec in enumerate(iter(vcf_in.fetch(contig = chrom, start = start, stop = stop))):\n",
    "        \n",
    "        if vcf_record_idx%images_per_subdir==0:\n",
    "            #switch to a new subdir if the current one already has enough batches\n",
    "            batch_subdir = str(vcf_record_idx//images_per_subdir)\n",
    "            os.makedirs(os.path.join(output_dir, batch_subdir), exist_ok = True)\n",
    "                        \n",
    "        if max_variants and vcf_record_idx > max_variants:\n",
    "            break\n",
    "            \n",
    "        #in a VCF file we have BAM sample names and we need the names of corresponding BAM files        \n",
    "        if 'BAM' in rec.info.keys():\n",
    "            #if the BAM file name is included in the VCF record\n",
    "            bam_file_name = rec.info.get('BAM')[0].replace('.bam','')+'.bam' #when the BAM file name is defined in the INFO field\n",
    "            bam_file_names = [bam_file_name] #for compatibility\n",
    "        else:\n",
    "            #otherwise, get the file name from the matching table\n",
    "            bam_sample_names = [s for s in all_samples if rec.samples[s]['GT']!=(None,None)]\n",
    "            bam_file_names = bam_matching.loc[bam_sample_names]\n",
    "\n",
    "        #loop over all BAM files that have this variant\n",
    "        for bam_file_name in bam_file_names:\n",
    "                    \n",
    "                #DP = rec.samples[bam_sample_name]['DP'] \n",
    "                #AD = rec.samples[bam_sample_name]['AD'] \n",
    "                #if DP==0:\n",
    "                #    continue   \n",
    "                #VAF = AD[1]/AD.sum()*100    \n",
    "                \n",
    "                #extract variant annotations\n",
    "                \n",
    "                variant_annotations = {}\n",
    "                \n",
    "                for ann_name in ['gnomAD_AF', 'GERMLINE']: #extra annotations from the VCF INFO field\n",
    "                    if ann_name in rec.info.keys():\n",
    "                        variant_annotations[ann_name] = rec.info.get(ann_name)\n",
    "                    else:\n",
    "                        variant_annotations[ann_name] = None\n",
    " \n",
    "                bam_path = os.path.join(bam_dir, bam_file_name) #full path to the BAM file\n",
    "                \n",
    "                variant = {'pos':rec.pos, 'refpos':rec.pos, 'chrom':rec.chrom, 'ref':rec.ref, 'alt':rec.alts[0]}\n",
    "                                \n",
    "                if data_augmentation:\n",
    "                    variant_to_replace = replacement_df.iloc[vcf_record_idx].to_dict()\n",
    "                    variant_to_replace['refpos'] = variant_to_replace['pos']\n",
    "                else:\n",
    "                    variant_to_replace = None\n",
    "\n",
    "                try:\n",
    "                    \n",
    "                    #get a tensor variant image for the current variant\n",
    "                    image, ref_support, VAF, DP = variant_to_image(variant, refgen_fa, bam_path,\n",
    "                        new_variant = variant_to_replace, **image_opts)\n",
    "\n",
    "                except Exception as exc:\n",
    "                    \n",
    "                    print('Exception occured while creating a variant image')\n",
    "                    print('Variant:\\n', variant)\n",
    "                    print('Varinat to replace:\\n', variant_to_replace)\n",
    "                    print('Reference FASTA file:\\n', refgen_fa)\n",
    "                    print('BAM file:\\n', bam_path)\n",
    "                    print('Error message:\\n', exc)\n",
    "\n",
    "                    continue\n",
    "\n",
    "                variants_batch.append(image) #add current variant to the batch\n",
    "                                                \n",
    "                variant_record = {\n",
    "                     'vcf_record_idx':vcf_record_idx,\n",
    "                     'subdir': batch_subdir,\n",
    "                     'BAM': bam_file_name,\n",
    "                     'VAF': VAF,\n",
    "                     'DP': DP,\n",
    "                     'image_height':image['p_hot_reads'].shape[0],\n",
    "                     'ref_support': ref_support,\n",
    "                     'data_augmentation_random_state': data_augmentation_random_state,\n",
    "                    }\n",
    "                \n",
    "                variant_record.update(variant_annotations) #add extra annotations from the VCF INFO field\n",
    "                \n",
    "                if data_augmentation:\n",
    "                    \n",
    "                        variant_record.update(variant_to_replace)\n",
    "                        variant_record.update({'old_'+ann_name:ann_value for ann_name,ann_value in variant.items()})\n",
    "\n",
    "                else:\n",
    "                        variant_record.update(variant)\n",
    "                        variant_record.update({'old_'+ann_name:None for ann_name in variant.keys()})\n",
    "\n",
    "\n",
    "                variants_list.append(variant_record)\n",
    "\n",
    "                N_variants_added += 1\n",
    "                \n",
    "                if N_variants_added%Lbatch == 0:\n",
    "                    \n",
    "                    #save the batch to the disk when it is full\n",
    "                                  \n",
    "                    batch_name = f'{variants_list[-Lbatch][\"batch_name\"]}.imgb' #batch name: VCF record index of the 1st variant in the batch\n",
    "                    \n",
    "                    for i in range(-Lbatch,0):\n",
    "                        variants_list[i]['batch_name']=batch_name #mark batch name in the variants list\n",
    "    \n",
    "                    if not SIMULATE:\n",
    "                        #save batch to the disk\n",
    "                        dump_batch(variants_batch, variants_list[-Lbatch:], os.path.join(*[output_dir, batch_subdir, batch_name]))\n",
    "                \n",
    "                    variants_batch = [] #empty current batch\n",
    "   \n",
    "                    if  len(variants_list)>1000:\n",
    "                        #add variants_list to variants_df every 1000 images\n",
    "                        variants_df = variants_df.append(variants_list, ignore_index=True)\n",
    "                        variants_list = []    \n",
    "\n",
    "    N_batch = len(variants_batch)\n",
    "        \n",
    "    if N_batch:\n",
    "        \n",
    "        print(N_batch)\n",
    "        \n",
    "        batch_name = f'{variants_list[-Lbatch][\"batch_name\"]}.imgb' #batch name: VCF record index of the 1st variant in the batch\n",
    "        \n",
    "        for i in range(-N_batch,0):\n",
    "            variants_list[i]['batch_name']=batch_name #mark batch name in the variants list\n",
    "                    \n",
    "        if not SIMULATE:\n",
    "            #save batch to the disk\n",
    "            dump_batch(variants_batch, variants_list[-N_batch:], os.path.join(*[output_dir,  batch_subdir, batch_name]))\n",
    "    \n",
    "    variants_df = variants_df.append(variants_list, ignore_index=True)\n",
    "\n",
    "    return variants_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main workflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_params = dotdict({})\n",
    "\n",
    "input_params.vcf = '/storage/groups/epigenereg01/workspace/projects/vale/datasets/snvs/MLL/MLL_variants_list_20200804/vcfs/somatic_test.vcf.gz'#'/storage/groups/epigenereg01/workspace/projects/vale/datasets/snvs/GACA-CN/gnomAD_thr_0/vcfs/negative_train_nn.vcf.gz' #vcf file with variants\n",
    "input_params.output_dir = '/storage/groups/epigenereg01/workspace/projects/vale/datasets/snvs/MLL/MLL_variants_list_20200804/images/somatic_test2'#'/storage/groups/epigenereg01/workspace/projects/vale/datasets/snvs/GACA-CN/gnomAD_thr_0/images/' #output dir name\n",
    "input_params.chrom = None#'1' #chromosome name, to limit images generation to a particular contig\n",
    "input_params.bam_dir = '/storage/groups/epigenereg01/datasets/MLL-5000-genomes/matched_pairs/BAM/'#'/storage/groups/epigenereg01/workspace/projects/vale/data/icgc/GACA-CN/bam/' #folder with BAM files\n",
    "input_params.refgen_fa = '/storage/groups/epigenereg01/workspace/projects/vale/calling/MLL/resources_GRCh37/GRCh37.fa' #Reference genome FASTA file\n",
    "input_params.data_augmentation = 0 #use data augmentation by exchanging mutation context between reads \n",
    "input_params.data_augmentation_random_state = 0 #random state for data augmentation\n",
    "input_params.Lbatch = 1#4 #size of images batches\n",
    "input_params.bam_matching_csv = '' #matching table between BAM sample name and BAM file name (see make_images)\n",
    "input_params.image_width = 150 # image width: 2x the most probable read length\n",
    "input_params.image_max_height = 50 #max image height, the probability to have a read depth above this value should be small\n",
    "input_params.image_crop_strategy = 'topbottom' #how to crop variant image when read depth>image_max_height\n",
    "input_params.image_sort_by_variant = True #sort reads by base in the variant column\n",
    "input_params.image_check_variant_column = 0 #check if the variant is present in actual pileup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "SIMULATE = 0 #simulate, don't create any folders or wite any images to disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not SIMULATE:\n",
    "    os.makedirs(input_params.output_dir, exist_ok = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exception occured while creating a variant image\n",
      "Variant:\n",
      " {'pos': 115258744, 'refpos': 115258744, 'chrom': '1', 'ref': 'C', 'alt': 'T'}\n",
      "Varinat to replace:\n",
      " None\n",
      "Reference FASTA file:\n",
      " /storage/groups/epigenereg01/workspace/projects/vale/calling/MLL/resources_GRCh37/GRCh37.fa\n",
      "BAM file:\n",
      " /storage/groups/epigenereg01/datasets/MLL-5000-genomes/matched_pairs/BAM/p_0_59.tumor.bam\n",
      "Error message:\n",
      " BAM file not found\n",
      "Exception occured while creating a variant image\n",
      "Variant:\n",
      " {'pos': 115258748, 'refpos': 115258748, 'chrom': '1', 'ref': 'C', 'alt': 'T'}\n",
      "Varinat to replace:\n",
      " None\n",
      "Reference FASTA file:\n",
      " /storage/groups/epigenereg01/workspace/projects/vale/calling/MLL/resources_GRCh37/GRCh37.fa\n",
      "BAM file:\n",
      " /storage/groups/epigenereg01/datasets/MLL-5000-genomes/matched_pairs/BAM/p_0_52.tumor.bam\n",
      "Error message:\n",
      " BAM file not found\n",
      "Exception occured while creating a variant image\n",
      "Variant:\n",
      " {'pos': 73565732, 'refpos': 73565732, 'chrom': '10', 'ref': 'G', 'alt': 'T'}\n",
      "Varinat to replace:\n",
      " None\n",
      "Reference FASTA file:\n",
      " /storage/groups/epigenereg01/workspace/projects/vale/calling/MLL/resources_GRCh37/GRCh37.fa\n",
      "BAM file:\n",
      " /storage/groups/epigenereg01/datasets/MLL-5000-genomes/matched_pairs/BAM/p_0_72.tumor.bam\n",
      "Error message:\n",
      " BAM file not found\n",
      "/storage/groups/epigenereg01/workspace/projects/vale/datasets/snvs/MLL/MLL_variants_list_20200804/images/somatic_test2\n",
      "Finished successfully. Execution time: 0m 9.1s.\n"
     ]
    }
   ],
   "source": [
    "gen_params =  {\n",
    "'start': None, #start from this record in the VCF\n",
    "'stop': None,  #stop at this record in the VCF\n",
    "'max_variants': 10, #maximum number of variants from this VCF to consider\n",
    "} #how to treat input VCF\n",
    "\n",
    "image_opts = dict() #parameters for the variant_to_image function\n",
    "\n",
    "for param,value in input_params.items():\n",
    "    #from input parameters, separate parameters for make_images and variant_to_image functions\n",
    "    if not param.startswith('image_'):\n",
    "        gen_params[param] = value\n",
    "    else:\n",
    "        image_opts[param] = value\n",
    "        \n",
    "if gen_params['chrom'] != None:\n",
    "    #if we are limited to a particular contig, put generated images in a dedicated folder\n",
    "    gen_params['output_dir'] = os.path.join(gen_params['output_dir'], gen_params['chrom'])\n",
    "    \n",
    "t0 = time.time()\n",
    "\n",
    "variants_df = make_images(image_opts = image_opts, **gen_params) #dataframe with annotations of processed variants\n",
    "\n",
    "vcf_name = os.path.basename(input_params.vcf).replace('.vcf.gz', '') #VCF base name without extentension\n",
    "\n",
    "variants_df['vcf'] = vcf_name\n",
    "\n",
    "variants_df.to_csv(os.path.join(gen_params['output_dir'], \"variants.csv.gz\"))\n",
    "\n",
    "t_exec = time.time() - t0 #total execution time\n",
    "\n",
    "print(f\"{gen_params['output_dir']}\\nFinished successfully. Execution time: {t_exec//60:.0f}m {t_exec%60:.1f}s.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
